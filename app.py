import streamlit as st
import os
from groq import Groq
import random

from langchain.chains import ConversationChain, LLMChain
from langchain_core.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)

from langchain_core.messages import SystemMessage
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain_groq import ChatGroq
from langchain.prompts import PromptTemplate


def main():   
    # Get Groq API key
    api_key = [ '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',
                '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',
                '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',
                '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',
                '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']
    groq_api_key = random.choice(api_key)

    # The title and greeting message of the Streamlit application
    st.image('logo.png')
    st.write("Hello! I'm your friendly Coding chatbot. I can help answer your questions, provide information. I'm also super fast! Let's start our conversation!")

    background_image = """
    <style>
    [data-testid="stAppViewContainer"] > .main {
        background-image: url("https://i.ibb.co/f8r0Dst/bgfor.png");
        background-size: 100vw 100vh;
        background-position: center;  
        background-repeat: no-repeat;
    }
    [data-testid="stHeader"] {
    background-color: rgba(0, 0, 0, 0);
    }
    </style>
    """

    st.markdown(background_image, unsafe_allow_html=True)

    input_style = """
    <style>
    input[type="text"] {
        background-color: transparent;
        color: #a19eae;  
    }
    div[data-baseweb="base-input"] {
        background-color: transparent !important;
    }
    [data-testid="stAppViewContainer"] {
        background-color: transparent !important;
    }
    </style>
    """

    st.markdown(input_style, unsafe_allow_html=True)

    memory = ConversationBufferWindowMemory(k=10, memory_key="chat_history", return_messages=True)

    user_question = st.text_input("Ask a question:")

    # session state variable
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history=[]
    else:
        for message in st.session_state.chat_history:
            memory.save_context(
                {'input':message['User']},
                {'output':message['AI']}
                )

    groq_chat = ChatGroq(
            groq_api_key=groq_api_key, 
            model_name='mixtral-8x7b-32768'
    )

    if user_question:
        prompt = ChatPromptTemplate.from_messages(
            [
                SystemMessage(
                    content='You are a AI tutor who excels in problem solving and coding. You know nothing else'
                ),

                MessagesPlaceholder(
                    variable_name="chat_history"
                ),

                HumanMessagePromptTemplate.from_template(
                    "{human_input}"
                ),
            ]
        )

        # Create a conversation chain using the LangChain LLM (Language Learning Model)
        conversation = LLMChain(
            llm=groq_chat,  
            prompt=prompt,  
            verbose=True,   
            memory=memory,
        )
        
        # The chatbot's answer is generated by sending the full prompt to the Groq API.
        response = conversation.predict(human_input=user_question)
        message = {'User':user_question,'AI':response}
        st.session_state.chat_history.append(message)
        st.write("CODERSGPT:", response)

if __name__ == "__main__":
    main()





